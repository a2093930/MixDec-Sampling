{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fed4950-a875-4977-acb9-b94d6dc4bb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple/, http://mirrors.oa.com/pypi/web/simple/\n",
      "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
      "Collecting dgl-cu102==0.8\n",
      "  Downloading https://data.dgl.ai/wheels/dgl_cu102-0.8.0-cp39-cp39-manylinux1_x86_64.whl (156.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 156.2 MB 6.7 MB/s eta 0:00:01   |█▍                              | 7.0 MB 1.2 MB/s eta 0:02:01     |████                            | 19.7 MB 5.9 MB/s eta 0:00:24     |█████████                       | 44.4 MB 5.1 MB/s eta 0:00:22     |███████████████▎                | 74.7 MB 4.5 MB/s eta 0:00:19     |████████████████████▉           | 101.7 MB 5.1 MB/s eta 0:00:11     |████████████████████████        | 117.4 MB 1.2 MB/s eta 0:00:34     |████████████████████████████    | 136.6 MB 1.1 MB/s eta 0:00:18\n",
      "\u001b[?25hRequirement already satisfied: dglgo in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dgl-cu102==0.8) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dgl-cu102==0.8) (1.8.0)\n",
      "Requirement already satisfied: tqdm in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dgl-cu102==0.8) (4.64.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dgl-cu102==0.8) (2.25.1)\n",
      "Requirement already satisfied: networkx>=2.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dgl-cu102==0.8) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from requests>=2.19.0->dgl-cu102==0.8) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from requests>=2.19.0->dgl-cu102==0.8) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from requests>=2.19.0->dgl-cu102==0.8) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from requests>=2.19.0->dgl-cu102==0.8) (2.10)\n",
      "Requirement already satisfied: autopep8>=1.6.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dglgo) (1.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dglgo) (6.0)\n",
      "Requirement already satisfied: numpydoc>=1.1.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dglgo) (1.3.1)\n",
      "Requirement already satisfied: pydantic>=1.9.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dglgo) (1.9.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.20 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dglgo) (0.17.21)\n",
      "Requirement already satisfied: typer>=0.4.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dglgo) (0.4.1)\n",
      "Requirement already satisfied: isort>=5.10.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from dglgo) (5.10.1)\n",
      "Requirement already satisfied: toml in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from autopep8>=1.6.0->dglgo) (0.10.2)\n",
      "Requirement already satisfied: pycodestyle>=2.8.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from autopep8>=1.6.0->dglgo) (2.8.0)\n",
      "Requirement already satisfied: sphinx>=3.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from numpydoc>=1.1.0->dglgo) (4.5.0)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from numpydoc>=1.1.0->dglgo) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from pydantic>=1.9.0->dglgo) (4.2.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from ruamel.yaml>=0.17.20->dglgo) (0.2.6)\n",
      "Requirement already satisfied: Pygments>=2.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.8.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
      "Requirement already satisfied: packaging in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (20.9)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
      "Requirement already satisfied: babel>=1.3 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.9.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.7.12)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (4.11.3)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
      "Requirement already satisfied: imagesize in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (1.3.0)\n",
      "Requirement already satisfied: docutils<0.18,>=0.14 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from sphinx>=3.0->numpydoc>=1.1.0->dglgo) (0.17.1)\n",
      "Requirement already satisfied: pytz>=2015.7 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from babel>=1.3->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2021.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from importlib-metadata>=4.4->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (3.8.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from packaging->sphinx>=3.0->numpydoc>=1.1.0->dglgo) (2.4.7)\n",
      "Installing collected packages: dgl-cu102\n",
      "  Attempting uninstall: dgl-cu102\n",
      "    Found existing installation: dgl-cu102 0.8.1\n",
      "    Uninstalling dgl-cu102-0.8.1:\n",
      "      Successfully uninstalled dgl-cu102-0.8.1\n",
      "Successfully installed dgl-cu102-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dgl-cu102==0.8 dglgo -f https://data.dgl.ai/wheels/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8db045b-b293-456b-bb4f-9d88c6753a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple/, http://mirrors.oa.com/pypi/web/simple/\n",
      "Requirement already satisfied: tqdm in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (4.64.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b79a71-15cb-426a-999e-22c89fa37119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.12.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /data/miniconda3/envs/env-3.9.2\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=10.2\n",
      "    - torchaudio==0.10.1\n",
      "    - torchvision==0.11.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    blas-1.0                   |              mkl           6 KB\n",
      "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
      "    ca-certificates-2022.4.26  |       h06a4308_0         124 KB\n",
      "    certifi-2021.10.8          |   py39h06a4308_2         151 KB\n",
      "    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB\n",
      "    ffmpeg-4.3                 |       hf484d3e_0         9.9 MB  pytorch\n",
      "    freetype-2.11.0            |       h70c0345_0         618 KB\n",
      "    giflib-5.2.1               |       h7b6447c_0          78 KB\n",
      "    gmp-6.2.1                  |       h2531618_2         539 KB\n",
      "    gnutls-3.6.15              |       he1e5248_0         1.0 MB\n",
      "    intel-openmp-2021.4.0      |    h06a4308_3561         4.2 MB\n",
      "    jpeg-9e                    |       h7f8727e_0         240 KB\n",
      "    lame-3.100                 |       h7b6447c_0         323 KB\n",
      "    lcms2-2.12                 |       h3be6417_0         312 KB\n",
      "    libiconv-1.16              |       h7f8727e_2         736 KB\n",
      "    libidn2-2.3.2              |       h7f8727e_0          81 KB\n",
      "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
      "    libtasn1-4.16.0            |       h27cfd23_0          58 KB\n",
      "    libtiff-4.2.0              |       h85742a9_0         502 KB\n",
      "    libunistring-0.9.10        |       h27cfd23_0         536 KB\n",
      "    libuv-1.40.0               |       h7b6447c_0         736 KB\n",
      "    libwebp-1.2.2              |       h55f646e_0          80 KB\n",
      "    libwebp-base-1.2.2         |       h7f8727e_0         440 KB\n",
      "    lz4-c-1.9.3                |       h295c915_1         185 KB\n",
      "    mkl-2021.4.0               |     h06a4308_640       142.6 MB\n",
      "    mkl-service-2.4.0          |   py39h7f8727e_0          59 KB\n",
      "    mkl_fft-1.3.1              |   py39hd3c417c_0         182 KB\n",
      "    mkl_random-1.2.2           |   py39h51133e4_0         309 KB\n",
      "    nettle-3.7.3               |       hbbd107a_1         809 KB\n",
      "    numpy-1.21.5               |   py39he7a7128_2          10 KB\n",
      "    numpy-base-1.21.5          |   py39hf524024_2         4.9 MB\n",
      "    openh264-2.1.1             |       h4ff587b_0         711 KB\n",
      "    openssl-1.1.1n             |       h7f8727e_0         2.5 MB\n",
      "    pillow-9.0.1               |   py39h22f2fdc_0         669 KB\n",
      "    pytorch-1.10.1             |py3.9_cuda10.2_cudnn7.6.5_0       768.4 MB  pytorch\n",
      "    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n",
      "    six-1.16.0                 |     pyhd3eb1b0_1          18 KB\n",
      "    torchaudio-0.10.1          |       py39_cu102         4.5 MB  pytorch\n",
      "    torchvision-0.11.2         |       py39_cu102         8.7 MB  pytorch\n",
      "    typing_extensions-4.1.1    |     pyh06a4308_0          28 KB\n",
      "    zstd-1.4.9                 |       haebb681_0         480 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        1.29 GB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1\n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0\n",
      "  freetype           pkgs/main/linux-64::freetype-2.11.0-h70c0345_0\n",
      "  giflib             pkgs/main/linux-64::giflib-5.2.1-h7b6447c_0\n",
      "  gmp                pkgs/main/linux-64::gmp-6.2.1-h2531618_2\n",
      "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0\n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561\n",
      "  jpeg               pkgs/main/linux-64::jpeg-9e-h7f8727e_0\n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0\n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0\n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h7f8727e_2\n",
      "  libidn2            pkgs/main/linux-64::libidn2-2.3.2-h7f8727e_0\n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.16.0-h27cfd23_0\n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0\n",
      "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0\n",
      "  libuv              pkgs/main/linux-64::libuv-1.40.0-h7b6447c_0\n",
      "  libwebp            pkgs/main/linux-64::libwebp-1.2.2-h55f646e_0\n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.2-h7f8727e_0\n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h295c915_1\n",
      "  mkl                pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640\n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py39h7f8727e_0\n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.1-py39hd3c417c_0\n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py39h51133e4_0\n",
      "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1\n",
      "  numpy              pkgs/main/linux-64::numpy-1.21.5-py39he7a7128_2\n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.21.5-py39hf524024_2\n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0\n",
      "  pillow             pkgs/main/linux-64::pillow-9.0.1-py39h22f2fdc_0\n",
      "  pytorch            pytorch/linux-64::pytorch-1.10.1-py3.9_cuda10.2_cudnn7.6.5_0\n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda\n",
      "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1\n",
      "  torchaudio         pytorch/linux-64::torchaudio-0.10.1-py39_cu102\n",
      "  torchvision        pytorch/linux-64::torchvision-0.11.2-py39_cu102\n",
      "  typing_extensions  pkgs/main/noarch::typing_extensions-4.1.1-pyh06a4308_0\n",
      "  zstd               pkgs/main/linux-64::zstd-1.4.9-haebb681_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2021.4.13-h06a4308_1 --> 2022.4.26-h06a4308_0\n",
      "  certifi                          2020.12.5-py39h06a4308_0 --> 2021.10.8-py39h06a4308_2\n",
      "  openssl                                 1.1.1k-h27cfd23_0 --> 1.1.1n-h7f8727e_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "zstd-1.4.9           | 480 KB    | ##################################### | 100% \n",
      "libidn2-2.3.2        | 81 KB     | ##################################### | 100% \n",
      "six-1.16.0           | 18 KB     | ##################################### | 100% \n",
      "lame-3.100           | 323 KB    | ##################################### | 100% \n",
      "libunistring-0.9.10  | 536 KB    | ##################################### | 100% \n",
      "lz4-c-1.9.3          | 185 KB    | ##################################### | 100% \n",
      "openh264-2.1.1       | 711 KB    | ##################################### | 100% \n",
      "mkl-service-2.4.0    | 59 KB     | ##################################### | 100% \n",
      "mkl_fft-1.3.1        | 182 KB    | ##################################### | 100% \n",
      "torchvision-0.11.2   | 8.7 MB    | ##################################### | 100% \n",
      "lcms2-2.12           | 312 KB    | ##################################### | 100% \n",
      "giflib-5.2.1         | 78 KB     | ##################################### | 100% \n",
      "libtasn1-4.16.0      | 58 KB     | ##################################### | 100% \n",
      "bzip2-1.0.8          | 78 KB     | ##################################### | 100% \n",
      "freetype-2.11.0      | 618 KB    | ##################################### | 100% \n",
      "cudatoolkit-10.2.89  | 365.1 MB  | ##################################### | 100% \n",
      "blas-1.0             | 6 KB      | ##################################### | 100% \n",
      "pytorch-1.10.1       | 768.4 MB  | ##################################### | 100% \n",
      "mkl_random-1.2.2     | 309 KB    | ##################################### | 100% \n",
      "libtiff-4.2.0        | 502 KB    | ##################################### | 100% \n",
      "typing_extensions-4. | 28 KB     | ##################################### | 100% \n",
      "gmp-6.2.1            | 539 KB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 124 KB    | ##################################### | 100% \n",
      "mkl-2021.4.0         | 142.6 MB  | ##################################### | 100% \n",
      "libpng-1.6.37        | 278 KB    | ##################################### | 100% \n",
      "libwebp-1.2.2        | 80 KB     | ##################################### | 100% \n",
      "nettle-3.7.3         | 809 KB    | ##################################### | 100% \n",
      "jpeg-9e              | 240 KB    | ##################################### | 100% \n",
      "intel-openmp-2021.4. | 4.2 MB    | ##################################### | 100% \n",
      "libiconv-1.16        | 736 KB    | ##################################### | 100% \n",
      "gnutls-3.6.15        | 1.0 MB    | ##################################### | 100% \n",
      "libwebp-base-1.2.2   | 440 KB    | ##################################### | 100% \n",
      "libuv-1.40.0         | 736 KB    | ##################################### | 100% \n",
      "pillow-9.0.1         | 669 KB    | ##################################### | 100% \n",
      "certifi-2021.10.8    | 151 KB    | ##################################### | 100% \n",
      "pytorch-mutex-1.0    | 3 KB      | ##################################### | 100% \n",
      "numpy-1.21.5         | 10 KB     | ##################################### | 100% \n",
      "numpy-base-1.21.5    | 4.9 MB    | ##################################### | 100% \n",
      "torchaudio-0.10.1    | 4.5 MB    | ##################################### | 100% \n",
      "ffmpeg-4.3           | 9.9 MB    | ##################################### | 100% \n",
      "openssl-1.1.1n       | 2.5 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install torchvision==0.11.2 torchaudio==0.10.1 cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fa003b-3450-4b7d-9320-4c1e8e60325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and Extracting Packages\n",
      "######################################################################## | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install --use-local pytorch-1.10.2-py3.9_cuda10.2_cudnn7.6.5_0.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2decbfa8-beb6-44ec-af0e-7710eedf4f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple/, http://mirrors.oa.com/pypi/web/simple/\n",
      "Collecting matplotlib\n",
      "  Downloading http://mirrors.oa.com/pypi/web/packages/e1/81/0a73fe71098683a1f73243f18f419464ec109acae16811bf29c5d0dc173e/matplotlib-3.5.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.2 MB 5.0 MB/s eta 0:00:01    |████████████                    | 4.2 MB 801 kB/s eta 0:00:09\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading http://mirrors.oa.com/pypi/web/packages/f6/13/2a187e2280251f5c035da46e1706d4c8bd6ccc9f34e88c298cffbc5ba793/kiwisolver-1.4.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading http://mirrors.oa.com/pypi/web/packages/2f/85/2f6e42fb4b537b9998835410578fb1973175b81691e9a82ab6668cf64b0b/fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 640 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from matplotlib) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading http://mirrors.oa.com/pypi/web/packages/5c/f9/695d6bedebd747e5eb0fe8fad57b72fdf25411273a39791cde838d5a8f51/cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.2 matplotlib-3.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0619ef-bac3-4704-9681-0213ef1e3310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple/, http://mirrors.oa.com/pypi/web/simple/\n",
      "Collecting pandas\n",
      "  Downloading http://mirrors.oa.com/pypi/web/packages/35/ad/616c27cade647c2a1513343c72c095146cf3e7a72ace6582574a334fb525/pandas-1.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e4603f-efdb-465e-b64e-556fd4edef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from transformers import BertTokenizer, BertModel, BertConfig\n",
    "# from torchsummary import summary\n",
    "from collections import Counter\n",
    "import math\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl.function as fn\n",
    "import os\n",
    "from dgl.data import DGLDataset\n",
    "import dgl\n",
    "from torch.utils.data import DataLoader\n",
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.cpu_count()\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72449529-7bef-485c-81b4-f850889a55d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b478917-4f88-4a03-b5f9-674c27e81f84",
   "metadata": {},
   "source": [
    "<font color =white> <h1>Data</h1>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1ad82-b336-4ee1-8631-8173f86445d1",
   "metadata": {},
   "source": [
    "<font color=white> <h1>dataset </h1>\n",
    "dataloader ？<br>\n",
    "process<br>\n",
    "save  ?<br>\n",
    "load ?<br>\n",
    "</font>columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120ded5-7f2c-482f-af94-6eab6e35d48e",
   "metadata": {},
   "source": [
    "<font color =white> <h1> 建图 </h1>\n",
    "    agg node: tag --- I2I  I2U U2U<br>\n",
    "              I  ---- I2I I2U T-T? U2U<br>\n",
    "                U ----  I2I  U2U <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf4bfa-478d-4e92-8683-78868c4ea004",
   "metadata": {},
   "source": [
    "<font color=white> <h1> 聚合方法</h1>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea844e8f-cff7-484e-bea8-0e163720590f",
   "metadata": {},
   "source": [
    "# <font color =white>aggreator :\n",
    "init  first <br>\n",
    "reset_p <br>\n",
    "agg_type  first  <br>\n",
    "activation <br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978e1a3e-02ec-4235-8c2c-b80aa7dfe949",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=('item','iagg','tag')\n",
    "s2=('item','iagg','user')#中间节点 T\n",
    "s3=('tag','tagg','user')\n",
    "s4=('tag','tagg','item')\n",
    "s5=('user','uagg','item')\n",
    "s6=('user','uagg','tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9174d2f-fba3-44dd-83dc-03004bd2e9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74922d10-f7b3-49d3-9b86-a43c8e6e6d9d",
   "metadata": {},
   "source": [
    "<font color =white><h1>ACG model :</h1>\n",
    "    init ?<br>\n",
    "    forward ?<br>\n",
    "    loss ?   第一版完成<br> \n",
    "    v 和K-hop Neig<br>\n",
    "    load \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17dcd0a-eb60-44d1-a0a4-760f77eb6afd",
   "metadata": {},
   "source": [
    "<font color=white> <h1>训练 </h1>\n",
    "dataloader ？<br>\n",
    "train   ？<br>\n",
    "graph   ？<br>\n",
    "loss   ？<br>\n",
    "optimizer ？<br>\n",
    "epoch    ？<br>\n",
    "layer   ？<br>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa23df6e-a9ff-4b8a-88b4-a34d4072edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_mix_graph(graph, k,emb,edge,train_idx=None,alpha=4):   #构造某类节点（用边打造的） 为核心的 聚合图 选出所有节点\n",
    "\n",
    "#         if(edges==s2): ##### 评估的edges\n",
    "#     edges=[s1,s2,s3] #it iu tu\n",
    "    edges=edge\n",
    "    mix_dic={}\n",
    "    h_mix_dic={}\n",
    "    \n",
    "#     for edge in edges: ###所有此类边对应的 两端点\n",
    "    t_src,_,t_dst=edge#### 节点和边\n",
    "    \n",
    "    h_mix_dic[t_src]=emb[t_src]\n",
    "    \n",
    "    src,dst=graph[edge].edges()\n",
    "    \n",
    "    h_mix_dic[t_src]=emb[t_src]\n",
    "    \n",
    "    tmp_dst=graph[edge].num_dst_nodes()\n",
    "\n",
    "    mix_src = src.repeat_interleave(k)#重复k次   用 源节点的 两边目的节点来组成\n",
    "    ori_dst = dst.repeat_interleave(k)\n",
    "\n",
    "    mix_dst = torch.tensor(range(mix_src.shape[0])).squeeze().to(device)\n",
    "\n",
    "    neg_dst = torch.randint(0, graph[edge].num_dst_nodes(), (len(dst) * k,1)).squeeze().to(device)\n",
    "    \n",
    "#     alpha=np.random.beta(alp,alp)\n",
    "    \n",
    "    mix_p=0.5*torch.ones(mix_src.shape[0],1).to(device)\n",
    "\n",
    "    h_dst=emb[t_dst][ori_dst]*mix_p+(1-mix_p)*emb[t_dst][neg_dst]\n",
    "#         print(h_dst,mix_p,mix_dic)\n",
    "    h_mix_dic[t_dst]=h_dst\n",
    "\n",
    "    mix_dic[edge]=(mix_src,mix_dst)\n",
    "        \n",
    "    g=dgl.heterograph(mix_dic)\n",
    "    \n",
    "#     print(h_mix_dic[t_src].shape,t_src,graph.num_nodes(t_src),g.num_nodes(t_src))\n",
    "    g=dgl.add_nodes(g, graph.num_nodes(t_src)-g.num_nodes(t_src),ntype=t_src)\n",
    "#     g=dgl.add_nodes(g, graph.num_nodes('item')-g.num_nodes('item'),ntype='item')\n",
    "#     print(g)\n",
    "    g=g.to(device)\n",
    " \n",
    "    return g,mix_p,h_mix_dic\n",
    "    \n",
    "    \n",
    "#     def construct_negative_graph_old(graph,edges, k,train_idx=None):\n",
    "\n",
    "#         if(edges==s2): ##### 评估的edges\n",
    "#             idx = graphs[edges].edges(form='eid')[train_idx]  ###所有此类边对应的 两端点\n",
    "#             src,dst=graphs[edges].find_edges(idx)\n",
    "#         else:\n",
    "#             src, dst = graphs[edges].edges()\n",
    "#         neg_src = src.repeat_interleave(k)#重复k次\n",
    "#         neg_dst = torch.randint(0, graph.num_nodes(), (len(src) * k,))\n",
    "#         return dgl.graph((neg_src, neg_dst), num_nodes=graph.num_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "852400fa-6d4e-4f9b-886a-fbca69fe8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_sim(graph,h,edge):\n",
    "    graph.ndata['h']=h\n",
    "    graph[edge].apply_edges(fn.u_dot_v('h','h','s'))\n",
    "    return graph.edata['s']\n",
    "def loss_mix(h,h_p):\n",
    "    loss_func=nn.KLDivLoss(reduction=\"batchmean\",log_target=True)\n",
    "#     loss_func=nn.KLDivLoss(reduction='mean',log_target=True)\n",
    "    return loss_func(h,h_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca32a6a5-67ba-4563-95fc-d4985a17638c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HeteroDotProductPredictor(nn.Module):\n",
    "    \n",
    "    def forward(self, graph, h):\n",
    "        # h是从5.1节中对异构图的每种类型的边所计算的节点表示\n",
    "        \n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "#             print('s\\n',graph.ndata['h'])\n",
    "            for edge in graph.canonical_etypes:\n",
    "                \n",
    "                graph.apply_edges(fn.u_dot_v('h', 'h', 's'), etype=edge)\n",
    "                \n",
    "            return graph.edata['s']\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def construct_negative_graph(graph, k,train_idx=None):   #构造某类节点（用边打造的） 为核心的 聚合图 选出所有节点\n",
    "\n",
    "#         if(edges==s2): ##### 评估的edges\n",
    "    edges=[s1,s2] #it iu tu\n",
    "    neg_dic={}\n",
    "    for edge in graph.canonical_etypes: ###所有此类边对应的 两端点\n",
    "        src,dst=graph[edge].edges()\n",
    "\n",
    "        neg_src = src.repeat_interleave(k)#重复k次   用 源节点的 两边目的节点来组成\n",
    "        neg_dst = torch.randint(0, graph[edge].num_dst_nodes(), (len(dst) * k,1)).squeeze().to(device)\n",
    "        neg_dic[edge]=(neg_src,neg_dst)\n",
    "    g=dgl.heterograph(neg_dic,num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes})\n",
    "    g=g.to(device)\n",
    " \n",
    "    return g\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        # 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型\n",
    "        self.conv1 = dgl.nn.HeteroGraphConv({\n",
    "            rel: dgl.nn.SAGEConv(in_feats, out_feats,'mean')\n",
    "            for rel in rel_names}, aggregate='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # 输入是节点的特征字典\n",
    "        h = self.conv1(graph, inputs)\n",
    "        return h\n",
    "    \n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rel_names,activation,bias=False,drop=0.1):\n",
    "        super().__init__()\n",
    "        self.n_hidden=in_features\n",
    "#         self.sage = RGCN(in_features, out_features, rel_names)\n",
    "#         self.sage2 = RGCN(in_features, out_features, rel_names)\n",
    "#         self.sage3 = RGCN(in_features, out_features, rel_names)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(RGCN(in_features, out_features, rel_names))\n",
    "        self.layers.append(RGCN(in_features, out_features, rel_names))\n",
    "        self.layers.append(RGCN(in_features, out_features, rel_names))\n",
    "#         self.similar=Dot_similar()\n",
    "        self.w_K=nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.weight=nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.w_s=nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.l_s=nn.Linear(in_features, out_features, bias=bias)\n",
    "        self.dropout=nn.Dropout(p=drop)\n",
    "        if activation[:-4] =='leakyrelu':\n",
    "            self.activation = nn.LeakyReLU(float(activation[-4:]))\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_hidden, 1))\n",
    "        \n",
    "    def aggx(self,edges):\n",
    "        return {'s': self.predictor(torch.mul(edges.dst['h'] ,edges.src['h'])) }\n",
    "    \n",
    "    def pred(self,graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "#             print('s\\n',graph.ndata['h'])\n",
    "            for edge in graph.canonical_etypes:\n",
    "                graph.apply_edges(self.aggx, etype=edge)\n",
    "                \n",
    "            return graph.edata['s']\n",
    "        \n",
    "            \n",
    "    def forward(self, blocks, emb):  #计算正负图的相似度\n",
    "        h=emb\n",
    "        for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n",
    "            h = layer(block, h)\n",
    "#             h1= layer(block, blocks[l].ndata['h'])\n",
    "            if l != len(self.layers) - 1:\n",
    "                for x in h:\n",
    "#                     h[x]=self.dropout(h[x])\n",
    "                    h[x]=self.activation(h[x])\n",
    "        for x in h:\n",
    "#             h3[x]=self.w_K(h3[x])+self.weight(h2[x])+self.w_s(h[x])\n",
    "            \n",
    "            h[x]=torch.nn.functional.normalize(h[x])   \n",
    "                \n",
    "        return h  \n",
    "    \n",
    "    def inference(self, g, device, batch_size, num_workers=0, buffer_device=None):\n",
    "    # The difference between this inference function and the one in the official\n",
    "    # example is that the intermediate results can also benefit from prefetching.\n",
    "        train_nid = {ntype: g.nodes(ntype=ntype) for ntype in g.ntypes}\n",
    "        \n",
    "        feat = g.ndata['h']\n",
    "        sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)\n",
    "        dataloader = dgl.dataloading.NodeDataLoader(\n",
    "                g, train_nid, sampler, device=device,\n",
    "                batch_size=batch_size, shuffle=False, drop_last=False, num_workers=num_workers)\n",
    "        \n",
    "        if buffer_device is None:\n",
    "            buffer_device = device\n",
    "\n",
    "        for l, layer in enumerate(self.layers):\n",
    "#             y = torch.zeros(g.num_nodes(), self.n_hidden, device=buffer_device)\n",
    "#             feat = feat.to(device)\n",
    "            y={}\n",
    "            for x in g.ntypes:\n",
    "                y[x]=torch.zeros(g.num_nodes(x),self.n_hidden, device=buffer_device)\n",
    "            for input_nodes, output_nodes, blocks in dataloader:\n",
    "                emb = {ntype: feat[ntype][input_nodes[ntype]] for ntype in input_nodes}\n",
    "#                 print(emb)\n",
    "#                 print(blocks[0].ndata['h'])\n",
    "                \n",
    "                h = layer(blocks[0], emb)\n",
    "#                 print(h)\n",
    "                if l != len(self.layers) - 1:\n",
    "#                       h = F.relu(h)\n",
    "                    h[x]=self.activation(h[x])\n",
    "                if l==len(self.layers) - 1:\n",
    "                    for x in output_nodes:\n",
    "#                         \n",
    "                        h[x]=torch.nn.functional.normalize(h[x])\n",
    "                for x in output_nodes:\n",
    "# print(y,'\\n-------------',h,'\\n-------------',output_nodes)\n",
    "                    y[x][output_nodes[x]] = h[x]\n",
    "#             print(y)\n",
    "            feat = y\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab58c39-2678-4c49-b4b5-4a71e11e43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSampler(object):\n",
    "    def __init__(self, g, k):\n",
    "        # 缓存概率分布\n",
    "        self.weights = {\n",
    "            etype: g.in_degrees(etype=etype).float() ** 0.75\n",
    "            for etype in g.canonical_etypes\n",
    "        }\n",
    "        self.k = k\n",
    "\n",
    "    def __call__(self, g, eids_dict):\n",
    "        result_dict = {}\n",
    "        for etype, eids in eids_dict.items():\n",
    "            src, _ = g.find_edges(eids, etype=etype)\n",
    "            src = src.repeat_interleave(self.k)\n",
    "            dst = self.weights[etype].multinomial(len(src), replacement=True)\n",
    "            result_dict[etype] = (src, dst)\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f074dc-7cd0-4605-b8ec-62066aa1e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun=nn.BCEWithLogitsLoss(reduction='mean')\n",
    "# loss_fun=nn.KLDivLoss(reduction=\"batchmean\",log_target=True)\n",
    "pred = HeteroDotProductPredictor()\n",
    "\n",
    "def simi_p_n(graph, ne_g , emb):\n",
    "#         h=self.forward(graph,emb)\n",
    "    return pred(graph, emb), pred(ne_g, emb)\n",
    "def lossf( pos,neg,k):\n",
    "        loss=0\n",
    "        for edge in pos:\n",
    "            edge_p=pos[edge].shape[0]\n",
    "            edge_n=neg[edge].shape[0]\n",
    "#             print(pos[edge])\n",
    "#             print(self.loss_fun(pos[edge].clamp(0),torch.ones(edge_p)),self.loss_fun(neg[edge].clamp(0),torch.zeros(edge_n)))\n",
    "#             loss+=(self.loss_fun(pos[edge].clamp(0),torch.ones(edge_p))+self.loss_fun(neg[edge].clamp(0),torch.zeros(edge_n)))\n",
    "            loss+=loss_fun(pos[edge].squeeze(),torch.ones(edge_p).to(device))\n",
    "            loss+=loss_fun(neg[edge].squeeze(),torch.zeros(edge_n).to(device))/k\n",
    "        #### \\sum -log_{pos}-log_{1-neg}\n",
    "        return loss\n",
    "\n",
    "s1=('item','iagg','tag')\n",
    "s2=('item','iagg','user')#中间节点 T\n",
    "s4=('tag','tagg','item')\n",
    "s5=('user','uagg','item')\n",
    "S=[s1,s2,s4,s5]\n",
    "\n",
    "def initi(init,node_features,graph,dim=128):\n",
    "#     for ntype in graph.ntypes:\n",
    "#             node_features[ntype]=torch.nn.Embedding(graph.num_nodes(ntype),dim).to(device) \n",
    "    if(init=='randn'):\n",
    "        for ntype in graph.ntypes:\n",
    "            node_features[ntype]=torch.randn(graph.num_nodes(ntype),dim,requires_grad = True).to(device) \n",
    "#             node_features[ntype]=torch.nn.functional.normalize(node_features[ntype] )\n",
    "    if(init=='rand'):\n",
    "        for ntype in graph.ntypes:\n",
    "            node_features[ntype]=torch.rand(graph.num_nodes(ntype),dim).to(device) \n",
    "    \n",
    "def train(train_dir,test_dir,dic,path,name,init='randn',u2i = 5,epochs=2000,k=10,k_m=5,meth='mean',lr=0.001,\n",
    "          activation ='leakyrelu',dim=128,decay=0.8,mix=False,batch_size=4096):\n",
    "    \n",
    "    time_start=time.time()\n",
    "    \n",
    "    graph=dgl.load_graphs(train_dir)[0][0]\n",
    "    g_test=dgl.load_graphs(test_dir)[0][0]\n",
    "    dic=torch.load(dic)\n",
    "    print('graph builded,num_nodes_user:',graph.num_nodes('user'),'num_node_item',graph.num_nodes('item'),'num_edges:',graph.num_edges(etype=s5))\n",
    "    print('test_graph builded,num_nodes_user:',g_test.num_nodes('user'),'num_node_item',g_test.num_nodes('item'),'num_edges:',g_test.num_edges(etype=s5))\n",
    "    node_features ={}\n",
    "#     graph.nodes['user'].data['h']=torch.randn(graph.num_nodes('user'),128)\n",
    "#     graph.nodes['tag'].data['h']=torch.randn(graph.num_nodes('tag'),128)\n",
    "#     graph.nodes['item'].data['h']=torch.randn(graph.num_nodes('item'),128)\n",
    "    initi(init,node_features,graph,dim)\n",
    "    g_test=g_test.to(device)\n",
    "    graph=graph.to(device) \n",
    "    graph.ndata['h']=node_features\n",
    "    print(graph.device)\n",
    "#     node_features = graph.ndata['h']\n",
    "#     print(node_features, graph.ndata)\n",
    "    n_features = node_features['item'].shape[1]\n",
    "    \n",
    "    print(\"node_dim={},neg_fig =pos x {},num_edges:{}\".format(n_features,k,graph[s2].num_edges()))\n",
    "    model = SAGE(dim,dim,graph.etypes,activation).to(device)\n",
    "#     model=RGCN(dim,dim,graph.etypes).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(),lr=lr,weight_decay=decay)\n",
    "    \n",
    "    train_eid = {etype: graph.edges(etype=etype, form='eid')\n",
    "    for etype in graph.canonical_etypes}\n",
    "    \n",
    "    sampler = dgl.dataloading.MultiLayerFullNeighborSampler(3)\n",
    "    \n",
    "    dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    graph, train_eid, sampler,device=device,\n",
    "    negative_sampler=dgl.dataloading.negative_sampler.PerSourceUniform(k),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "#     pin_prefetcher=True,\n",
    "    num_workers=0)\n",
    "    \n",
    "    max_evl=0\n",
    "    train_pred,evl_score,mrr=evaluate(model,g_test,graph,batch_size,dic)\n",
    "    print('start:',train_pred,evl_score,mrr)\n",
    "    for epoch in range(epochs+1):\n",
    "        torch.cuda.empty_cache()\n",
    "#         print(graph.ndata)\n",
    "        loss_all=0\n",
    "        for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
    "            \n",
    "            blocks = [b.to(torch.device('cuda')) for b in blocks]\n",
    "            positive_graph = positive_graph.to(device)\n",
    "            negative_graph = negative_graph.to(device)\n",
    "            \n",
    "            features=blocks[0].ndata['h']\n",
    "#         negative_graph = construct_negative_graph(graph, 1).to(device)\n",
    "            h=model(blocks,features)\n",
    "#         print(h)\n",
    "            loss_m=0\n",
    "            if mix==True:\n",
    "    #             for edge in graph.canonical_etypes: \n",
    "                for edge in graph.canonical_etypes:\n",
    "        #             print(xx[0].edges(),xx)\n",
    "                    mix_graph,label,h_mix = construct_mix_graph(blocks[0],k_m,h,edge)\n",
    "\n",
    "                    mix_s=mix_sim(mix_graph,h_mix,edge)\n",
    "                    mix_s=torch.sigmoid(mix_s)\n",
    "    #                 print(mix_s)\n",
    "                    loss_m+=loss_mix(mix_s,label)\n",
    "#             print(loss_m)\n",
    "            pos_score, neg_score = simi_p_n(positive_graph, negative_graph,h)###聚合用 e ,生成图用 pos_e\n",
    "#         print(pos_score, neg_score)\n",
    "        \n",
    "#         print(pos_score, neg_score)\n",
    "            loss=lossf(pos_score, neg_score,1)\n",
    "#             print(loss)\n",
    "            loss=loss+loss_m\n",
    "#         loss=model.loss(graph, negative_graph,h)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            loss_all+=loss.item()\n",
    "#         for name, parms in model.named_parameters():\t\n",
    "#             print('-->name:', name, '-->grad_requirs:',parms.requires_grad, \\\n",
    "#              ' -->grad_value:',parms.grad)  \n",
    "        if(epoch%10==0):\n",
    "            \n",
    "            train_pred,evl_score,mrr=evaluate(model,g_test,graph,batch_size,dic)\n",
    "            max_evl=max(max_evl,mrr)\n",
    "            print(\"train score :\",train_pred)\n",
    "            print(\"evl score and mrr: \",evl_score,mrr)    \n",
    "            print(\"epoch:{} ,loss:{} ,max_evl={}\".format(epoch,loss_all,max_evl))  \n",
    "#             print(h)\n",
    "#         if(epoch%1000==0):\n",
    "#             print(h)\n",
    "    time_end=time.time()\n",
    "    print('totally cost',time_end-time_start)\n",
    "\n",
    "    \n",
    "def evaluate(model,test_g,graph,batch_size,dic):\n",
    "    \n",
    "    \n",
    "    \n",
    "    s5=('user','uagg','item')\n",
    "#     print(test_g.num_edges(etype=s5))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        h=model.inference(graph,device,batch_size)####传入graph.ndata\n",
    "        test_g.ndata['h']=h\n",
    "#         graph.ndata['h']=h\n",
    "        g_u=torch.split(graph.edges(etype=s5)[0],400)\n",
    "        g_i=torch.split(graph.edges(etype=s5)[1],400)\n",
    "        train_pred=0\n",
    "        for u,i in zip(g_u,g_i):\n",
    "            train_pred+=(torch.sigmoid(h['user'][u]*h['item'][i]).sum(dim=1)>=0.5).sum()\n",
    "            \n",
    "        train_pred=train_pred.to(torch.float)\n",
    "        train_pred/=graph.num_edges(etype=s5)\n",
    "    \n",
    "        mrr_sum=0\n",
    "#         for x,y in zip(test_g.edges(etype=s5)[0],test_g.edges(etype=s5)[1]):\n",
    "            \n",
    "#             print(x,y)\n",
    "        u_list=test_g.edges(etype=s5)[0]\n",
    "        i_list=test_g.edges(etype=s5)[1]\n",
    "        for u,i in zip(u_list,i_list):\n",
    "#             print(u,i)\n",
    "            x=h['user'][u]\n",
    "            y=h['item'].t()\n",
    "            z=h['item'][i].t()\n",
    "            ma1=torch.sigmoid(x@y)\n",
    "            ma2=torch.sigmoid((x@z))\n",
    "            ma1[dic[u.item()]]=-2\n",
    "#             print(ma1,ma2)\n",
    "            mrr_sum+=(1/((ma1-ma2>=0).sum()+1))\n",
    "\n",
    "        \n",
    "        mrr=mrr_sum/test_g.num_edges(etype=s5)     \n",
    "    \n",
    "#         test_g.apply_edges(lambda edges: {'s' : torch.cosine_similarity( edges.src['h'],edges.dst['h'])})\n",
    "        test_g.apply_edges(fn.u_dot_v('h','h','s'))\n",
    "        score=torch.sigmoid(test_g[s5].edata['s'].squeeze())\n",
    "        \n",
    "#         print(score,sum(score>0.5),score.shape[0])\n",
    "#         print(score)\n",
    "        pred=sum(score>=0.5)/score.shape[0]\n",
    "    \n",
    "    return train_pred,pred,mrr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46662170-c288-41bd-9abf-cb5c00330b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph builded,num_nodes_user: 70679 num_node_item 24915 num_edges: 652514\n",
      "test_graph builded,num_nodes_user: 70679 num_node_item 24915 num_edges: 193920\n",
      "cuda:0\n",
      "node_dim=384,neg_fig =pos x 30,num_edges:652514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages/dgl/base.py:45: DGLWarning: EdgeDataLoader directly taking a BlockSampler will be deprecated and it will not support feature prefetching. Please use dgl.dataloading.as_edge_prediction_sampler to wrap it.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: tensor(1., device='cuda:0') tensor(0.5910, device='cuda:0') tensor(0.0004, device='cuda:0')\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.7980, device='cuda:0') tensor(0.0056, device='cuda:0')\n",
      "epoch:0 ,loss:744.2545506954193 ,max_evl=0.005594643298536539\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8138, device='cuda:0') tensor(0.0084, device='cuda:0')\n",
      "epoch:10 ,loss:693.8885500431061 ,max_evl=0.008403455838561058\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8289, device='cuda:0') tensor(0.0089, device='cuda:0')\n",
      "epoch:20 ,loss:691.9872283935547 ,max_evl=0.008916841819882393\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8381, device='cuda:0') tensor(0.0097, device='cuda:0')\n",
      "epoch:30 ,loss:691.3965311050415 ,max_evl=0.009716731496155262\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8379, device='cuda:0') tensor(0.0098, device='cuda:0')\n",
      "epoch:40 ,loss:691.186680316925 ,max_evl=0.009834440425038338\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8434, device='cuda:0') tensor(0.0101, device='cuda:0')\n",
      "epoch:50 ,loss:691.0337455272675 ,max_evl=0.01006955374032259\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8471, device='cuda:0') tensor(0.0107, device='cuda:0')\n",
      "epoch:60 ,loss:690.9580674171448 ,max_evl=0.010664647445082664\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8482, device='cuda:0') tensor(0.0104, device='cuda:0')\n",
      "epoch:70 ,loss:690.8496906757355 ,max_evl=0.010664647445082664\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8458, device='cuda:0') tensor(0.0103, device='cuda:0')\n",
      "epoch:80 ,loss:690.7853951454163 ,max_evl=0.010664647445082664\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8496, device='cuda:0') tensor(0.0107, device='cuda:0')\n",
      "epoch:90 ,loss:690.6925690174103 ,max_evl=0.010664647445082664\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8548, device='cuda:0') tensor(0.0102, device='cuda:0')\n",
      "epoch:100 ,loss:690.6806883811951 ,max_evl=0.010664647445082664\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8539, device='cuda:0') tensor(0.0110, device='cuda:0')\n",
      "epoch:110 ,loss:690.6418335437775 ,max_evl=0.01099992636591196\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8505, device='cuda:0') tensor(0.0105, device='cuda:0')\n",
      "epoch:120 ,loss:690.6037867069244 ,max_evl=0.01099992636591196\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8552, device='cuda:0') tensor(0.0104, device='cuda:0')\n",
      "epoch:130 ,loss:690.51225233078 ,max_evl=0.01099992636591196\n",
      "train score : tensor(1., device='cuda:0')\n",
      "evl score and mrr:  tensor(0.8574, device='cuda:0') tensor(0.0107, device='cuda:0')\n",
      "epoch:140 ,loss:690.4973571300507 ,max_evl=0.01099992636591196\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a6c00cc98f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(train_dir='Data/amazon-book/graph',test_dir='Data/amazon-book/graph_test',path='./',name='5corebook',init='randn',\\\n\u001b[0m\u001b[1;32m      2\u001b[0m       u2i =10,epochs=2500,k=30,k_m=5,lr=0.001,activation ='leakyrelu0.20',dim=384,decay=0,mix=False,batch_size=4096)\n",
      "\u001b[0;32m<ipython-input-10-a9f03c0bf8f9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dir, test_dir, path, name, init, u2i, epochs, k, k_m, meth, lr, activation, dim, decay, mix, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m#         loss=model.loss(graph, negative_graph,h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mloss_all\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/env-3.9.2/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dir='Data/amazon-book/graph',test_dir='Data/amazon-book/graph_test',dic='Data/amazon-book/mrr',path='./',name='5corebook',init='randn',\\\n",
    "      u2i =10,epochs=2500,k=30,k_m=5,lr=0.001,activation ='leakyrelu0.20',dim=384,decay=0,mix=False,batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272b0d2-5ed6-4c08-90d0-4f6517af4bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceea61c3-b8bc-4ce3-88e5-73088927c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        # 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型\n",
    "        self.conv1 = dgl.nn.HeteroGraphConv({\n",
    "            rel: dgl.nn.SAGEConv(in_feats, out_feats,'mean')\n",
    "            for rel in rel_names}, aggregate='mean')\n",
    "        self.loss_fun=nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.pred = HeteroDotProductPredictor()\n",
    "        \n",
    "    def forward(self, graph, inputs):\n",
    "        # 输入是节点的特征字典\n",
    "        h = self.conv1(graph, inputs)\n",
    "        return h\n",
    "    def simi_p_n(self,graph, ne_g , emb):\n",
    "#         h=self.forward(graph,emb)\n",
    "        return self.pred(graph, emb), self.pred(ne_g, emb)\n",
    "    \n",
    "    def loss(self, pos,neg):\n",
    "        loss=0\n",
    "         # it iu \n",
    "#         print(pos)\n",
    "        for edge in pos:\n",
    "            edge_p=pos[edge].shape[0]\n",
    "            edge_n=neg[edge].shape[0]\n",
    "#             print(pos[edge])\n",
    "#             print(self.loss_fun(pos[edge].clamp(0),torch.ones(edge_p)),self.loss_fun(neg[edge].clamp(0),torch.zeros(edge_n)))\n",
    "#             loss+=(self.loss_fun(pos[edge].clamp(0),torch.ones(edge_p))+self.loss_fun(neg[edge].clamp(0),torch.zeros(edge_n)))\n",
    "            loss=self.loss_fun(pos[edge].squeeze(),torch.ones(edge_p).to(device))\n",
    "            loss+=self.loss_fun(neg[edge].squeeze(),torch.zeros(edge_n).to(device))\n",
    "        #### \\sum -log_{pos}-log_{1-neg}\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2650ab9-c5a0-4db6-9318-0707972539e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e33a8e-8502-4af2-a61d-24a9ee5c9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(0, g_test.num_nodes('item'), (499,1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04138ea7-6148-4831-9272-d370cf10879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.heterograph({\n",
    "    ('user', 'follows', 'user'): ([0, 1], [1, 1]),\n",
    "    ('game', 'attracts', 'user'): ([0,2], [1,0])\n",
    "})\n",
    "g.nodes['user'].data['h'] = torch.tensor([[1.,1], [2.,2]])\n",
    "g.nodes['game'].data['h'] = torch.tensor([[1.,1],[1.,2],[1.,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab4f829-cae5-4df3-a7d0-d096d660cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss1=('tag','tagg','item')\n",
    "# ss2=('user','uagg','item')#中间节点 T\n",
    "# ss3=('tag','tagg','user')\n",
    "\n",
    "ss1=('item','iagg','tag')\n",
    "ss2=('item','iagg','user')#中间节点 T\n",
    "ss3=('tag','tagg','user')\n",
    "\n",
    "class Dot_similar(nn.Module):\n",
    "    def forward(self, graph,emb):\n",
    "        edges=[ss1,ss2]\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h']=emb\n",
    "            for edge in edges:\n",
    "#                 graph[edge].apply_edges(lambda edges: {'s': torch.cosine_similarity( edges.src['h'],edges.dst['h'])})\n",
    "                graph[edge].apply_edges(fn.u_dot_v('h','h','s'))\n",
    "            return graph.edata['s']\n",
    "        \n",
    "def construct_negative_graph(graph, k,train_idx=None):   #构造某类节点（用边打造的） 为核心的 聚合图 选出所有节点\n",
    "\n",
    "#         if(edges==s2): ##### 评估的edges\n",
    "    edges=[ss1,ss2] #it iu tu\n",
    "    neg_dic={}\n",
    "    for edge in edges: ###所有此类边对应的 两端点\n",
    "        src,dst=graph[edge].edges()\n",
    "\n",
    "        neg_src = src.repeat_interleave(k)#重复k次   用 源节点的 两边目的节点来组成\n",
    "        neg_dst = torch.randint(0, graph[edge].num_dst_nodes(), (len(dst) * k,1)).squeeze().to(device)\n",
    "        neg_dic[edge]=(neg_src,neg_dst)\n",
    "    g=dgl.heterograph(neg_dic)\n",
    "    g=g.to(device)\n",
    " \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1a0efc-b4f8-4fb5-99ab-fe57936de3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticTwoLayerRGCN(nn.Module):\n",
    "    def __init__(self, in_feat, hidden_feat, out_feat, rel_names):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "                rel : dglnn.GraphConv(in_feat, hidden_feat, norm='right')###对每种类型定义卷积方式\n",
    "                for rel in rel_names\n",
    "            })\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "                rel : dglnn.GraphConv(hidden_feat, out_feat, norm='right')\n",
    "                for rel in rel_names\n",
    "            })\n",
    "\n",
    "    def forward(self, blocks, x):\n",
    "        x = self.conv1(blocks[0], x)\n",
    "        x = self.conv2(blocks[1], x)\n",
    "        return x\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_classes,\n",
    "                 etypes):\n",
    "        super().__init__()\n",
    "        self.rgcn = StochasticTwoLayerRGCN(\n",
    "            in_features, hidden_features, out_features, etypes)\n",
    "        self.pred = ScorePredictor()\n",
    "\n",
    "    def forward(self, positive_graph, negative_graph, blocks, x):\n",
    "        x = self.rgcn(blocks, x)\n",
    "        pos_score = self.pred(positive_graph, x)\n",
    "        neg_score = self.pred(negative_graph, x)\n",
    "        return pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3861e0e7-4c69-4d9d-8e42-c297521933a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c4d903f1e6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# xx=nn.BCELoss()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "# xx=nn.BCELoss()\n",
    "xx(torch.tensor([0.,1,0]),torch.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64093860-6ddd-4b3a-82b0-e926f14e565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(<class 'dict'>, {'h': {'game': tensor([[1.]]), 'user': tensor([[1.0000],\n",
       "         [2.0000],\n",
       "         [0.2319],\n",
       "         [0.2252]])}}),\n",
       " Graph(num_nodes={'game': 1, 'user': 4},\n",
       "       num_edges={('game', 'attracts', 'user'): 1, ('user', 'follows', 'user'): 2},\n",
       "       metagraph=[('game', 'user', 'attracts'), ('user', 'user', 'follows')]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.add_nodes(ntype='user',num=1,data={'h':torch.rand(1,1)})\n",
    "\n",
    "g.nodes['user'].data['h']\n",
    "g.ndata,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53a77a74-52c1-4023-a4fe-057dc2728ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_edges(torch.tensor([1, 3]), torch.tensor([0, 1]),etype='follows',data={ 'w': torch.ones(2, 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217dd0a0-a15b-43b8-b8f8-648267559c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dic(x ,dic):\n",
    "    \n",
    "    if type(x) == dict:\n",
    "        if 'ASIN: ' in x:\n",
    "            x.pop('ASIN: ')\n",
    "        x=list(x.values())\n",
    "    if type(x) ==list:\n",
    "        for t in x:\n",
    "            dic.setdefault(t,0)\n",
    "            dic[t]+=1\n",
    "    else:\n",
    "        dic.setdefault(x,0)\n",
    "        dic[x]+=1\n",
    "                \n",
    "def get_dict_json(df,name ,k=0) -> dict: ## 选出 出现次数大于k的实体\n",
    "    df=parse(df)\n",
    "    cnt=0\n",
    "    dic={}              \n",
    "    for pp in tqdm(df):\n",
    "#         print(pp)\n",
    "        if(type(name)==list):\n",
    "            for t in name:\n",
    "                if(t in pp):\n",
    "                    x=pp[t]\n",
    "                    make_dic(x,dic)\n",
    "                \n",
    "        else:\n",
    "            x=pp[name]\n",
    "            make_dic(x,dic)\n",
    "#     print(dic)\n",
    "\n",
    "    ans={}\n",
    "    \n",
    "    for x in dic:\n",
    "        if(dic[x]>k):\n",
    "            ans[x]=cnt\n",
    "            cnt+=1\n",
    "\n",
    "    return ans\n",
    "def sr_ds_json(df,sr,ds,sr_dic,ds_dic):\n",
    "    df=parse(df)\n",
    "    nsr,nds=[],[]\n",
    "    for tem in tqdm(df):\n",
    "        x=tem[sr]\n",
    "        if(x not in sr_dic):\n",
    "            continue\n",
    "        if(type(ds)==list):\n",
    "            for yy in ds:\n",
    "                y=tem[yy]\n",
    "                if type(y)==dict :\n",
    "        \n",
    "                    for t in y.values():\n",
    "                        if( t in ds_dic and x in sr_dic):\n",
    "                            nsr.append(sr_dic[x])\n",
    "                            nds.append(ds_dic[t])\n",
    "                elif type(y)==list :\n",
    "\n",
    "                    for t in y:\n",
    "                        if( t in ds_dic and x in sr_dic):\n",
    "                            nsr.append(sr_dic[x])\n",
    "                            nds.append(ds_dic[t])\n",
    "                elif( y in ds_dic and x in sr_dic):\n",
    "                    nsr.append(sr_dic[x])\n",
    "                    nds.append(ds_dic[y])\n",
    "        elif (tem[ds] in ds_dic and x in sr_dic):\n",
    "            y=tem[ds]\n",
    "            nsr.append(sr_dic[x])\n",
    "            nds.append(ds_dic[y])\n",
    "##### 消除少于K条的节点          \n",
    "        \n",
    "    \n",
    "    return torch.tensor(nsr),torch.tensor(nds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ac48cb-564b-450c-8ed0-db3dbc6b853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import DGLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import gzip\n",
    "import json\n",
    "def parse(path):\n",
    "    with gzip.open(path,'rb') as g:\n",
    "#     g = gzip.open(path, 'rb')\n",
    "        for l in g:\n",
    "            yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def get_dict(df,name ,k=0) -> dict: ## 选出 出现次数大于k的实体\n",
    "    \n",
    "    cnt=0\n",
    "    dic={}\n",
    "    for x in df[name]:\n",
    "        if type(x) == dict:\n",
    "            if 'ASIN: ' in x:\n",
    "                x.pop('ASIN: ')\n",
    "            x=list(x.values())\n",
    "        if type(x) ==list:\n",
    "            for t in x:\n",
    "                dic.setdefault(t,0)\n",
    "                dic[t]+=1\n",
    "        else:\n",
    "            dic.setdefault(x,0)\n",
    "            dic[x]+=1\n",
    "#     print(dic)\n",
    "    ans={}\n",
    "    \n",
    "    for x in dic:\n",
    "        if(dic[x]>k):\n",
    "            ans[x]=cnt\n",
    "            cnt+=1\n",
    "\n",
    "    return ans\n",
    "\n",
    "    \n",
    "    \n",
    "def sr_ds(df,sr,ds,sr_dic,ds_dic):\n",
    "    sr,ds=df[sr].tolist(),df[ds].tolist()\n",
    "#     print(ds)\n",
    "    nsr,nds=[],[]\n",
    "    \n",
    "    for x,y in zip(sr,ds):\n",
    "        \n",
    "        if type(y)==dict :\n",
    "        \n",
    "            for t in y.values():\n",
    "                if( t in ds_dic and x in sr_dic):\n",
    "                    nsr.append(sr_dic[x])\n",
    "                    nds.append(ds_dic[t])\n",
    "        elif type(y)==list :\n",
    "            \n",
    "            for t in y:\n",
    "                if( t in ds_dic and x in sr_dic):\n",
    "                    nsr.append(sr_dic[x])\n",
    "                    nds.append(ds_dic[t])\n",
    "        elif( y in ds_dic and x in sr_dic):\n",
    "            nsr.append(sr_dic[x])\n",
    "            nds.append(ds_dic[y])\n",
    "            \n",
    "##### 消除少于K条的节点          \n",
    "        \n",
    "    \n",
    "    return torch.tensor(nsr),torch.tensor(nds)\n",
    "\n",
    "def get_mask(edge,num):\n",
    "    sr,ds=edge\n",
    "    n=sr.shape[0]\n",
    "    mask=torch.tensor([1]*n)\n",
    "    mask[random.sample(range(n),num)]=0\n",
    "    return mask\n",
    "\n",
    "def con_sr_ds(e1,e2):#中转投影\n",
    "\n",
    "    dic={}\n",
    "    for x,y in zip(e1[0].tolist(),e1[1].tolist()):#  i,t\n",
    "        dic.setdefault(x,[])\n",
    "        dic[x].append(y)\n",
    "#     print(dic)\n",
    "    edge_sr,edge_ds=[],[]\n",
    "    for x,y in zip(e2[0].tolist(),e2[1].tolist()):#i ,u\n",
    "        if(x in dic):\n",
    "            for i in dic[x]:\n",
    "                edge_sr.append(i)\n",
    "                edge_ds.append(y)\n",
    "    return torch.tensor(edge_sr),torch.tensor(edge_ds) # t 2 i\n",
    "\n",
    "def con_sr_ds_w(e1,e2):\n",
    "\n",
    "    dic={}\n",
    "    \n",
    "    for x,y in zip(e1[0].tolist(),e1[1].tolist()):#  i,t\n",
    "        dic.setdefault(x,[])\n",
    "        dic[x].append(y)\n",
    "#     print(dic)\n",
    "    \n",
    "    cdic={}\n",
    "    for x,y in zip(e2[0].tolist(),e2[1].tolist()):#i ,u\n",
    "#         if(x in dic):\n",
    "            for i in dic[x]:\n",
    "                if((i,y) not in cdic):\n",
    "                    cdic[(i,y)]=1\n",
    "                else:\n",
    "                    cdic[(i,y)]+=1\n",
    "    edge=torch.tensor(list(cdic.keys()))\n",
    "#     print(edge,torch.tensor(list(cdic.values())))\n",
    "    return edge[:,0],edge[:,1],torch.tensor(list(cdic.values()))   #t ,u ,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72ccf8-40e6-479a-b2ee-bf099696799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1118ec-c80b-4386-ba7b-a0141309b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "824c183c-35e6-4623-a2b7-e164141c6a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.has_edge_between([3,2],[2,1],'follows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b0427b-931b-45de-a759-f247dd90b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.read_table('Data/amazon-book/train.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d13859a-eaa6-4a51-828b-6b1d37e5ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACGDataset(DGLDataset):\n",
    "    def __init__(self, user_dir1,item_dir2,path,name,k=5):\n",
    "        super(ACGDataset).__init__()\n",
    "        print(os.path.join(path,name,str(k)))\n",
    "        if os.path.exists(os.path.join(path,name,str(k)))==False:\n",
    "            os.makedirs(os.path.join(path,name,str(k)))\n",
    "        self.g_dic=os.path.join(path,name,str(k),'dic.pt')\n",
    "        self.g_path=os.path.join(path,name,str(k),'graph.bin')\n",
    "        self.g_evl=os.path.join(path,name,str(k),'test')\n",
    "#         if(os.path.isfile(self.g_path)):\n",
    "#             return\n",
    "        self.user_dir=user_dir1\n",
    "        self.item_dir=item_dir2\n",
    "\n",
    "        self.k=k\n",
    "#         print(\"data user and item loaded,user:{},items{}\".format(self.raw_dir1.shape[0],self.raw_dir2.shape[0]))\n",
    "        \n",
    "    \n",
    "    \n",
    "    def process(self): ### 处理数据\n",
    "        #双向图\n",
    "        \n",
    "        if(os.path.isfile(self.g_path)):\n",
    "            self.tag,self.item,self.user =torch.load(self.g_dic)\n",
    "            return\n",
    "\n",
    "        df_u=getDF(user_dir1)[['reviewerID','asin']]\n",
    "        df_I=getDF(item_dir2)[['asin','feature','category','brand']]#brand,'details'\n",
    "\n",
    "        \n",
    "        self.item=get_dict(df_I,'asin')\n",
    "        self.tag=get_dict(df_I,'feature',k=self.k)\n",
    "#         print(self.tag)\n",
    "        self.tag.update(get_dict(df_I,'details',k=self.k))\n",
    "        self.tag.update(get_dict(df_I,'category',k=self.k))\n",
    "        self.tag.update(get_dict(df_I,'brand',k=self.k))\n",
    "        \n",
    "        self.user=get_dict(df_u,'reviewerID',k=self.k)#出现次数大于k的字典\n",
    "\n",
    "    def process_json(self): ### 处理数据\n",
    "        #双向图\n",
    "        \n",
    "        if(os.path.isfile(self.g_path)):\n",
    "            self.tag,self.item,self.user =torch.load(self.g_dic)\n",
    "            return \n",
    "\n",
    "        df_u=self.user_dir\n",
    "        #['reviewerID','asin','reviewTime']\n",
    "        df_I=self.item_dir\n",
    "#         ['asin','feature','category','brand']#brand,'details'\n",
    "        print(df_u,df_I)\n",
    "        self.item=get_dict_json(df_u,'asin',k=self.k)\n",
    "        print('item dic builded')\n",
    "        self.tag=get_dict_json(df_I,['feature','category','brand'],k=self.k)\n",
    "#         print(self.tag)\n",
    "        print('tag dic builded')\n",
    "        self.user=get_dict_json(df_u,'reviewerID',k=self.k)#出现次数大于k的字典\n",
    "        print(\"dic builded item:{},tag:{},user:{}\".format(len(self.item),len(self.tag),len(self.user)))\n",
    "        torch.save([self.tag,self.item,self.user],self.g_dic)\n",
    "#         print(self.user)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \n",
    "        if(os.path.isfile(self.g_path)):\n",
    "            self.val_edge,self.test_edge=torch.load(self.g_evl)\n",
    "            return dgl.load_graphs(self.g_path)\n",
    "        df_u=self.user_dir\n",
    "        #['reviewerID','asin','reviewTime']\n",
    "        df_I=self.item_dir\n",
    "        e1=sr_ds_json(df_I,'asin',['feature','category','brand'],self.item,self.tag)  #拿df item tag\n",
    "        sr1,ds1=e1\n",
    "        \n",
    "        print(\"edge i2t loaded\")\n",
    "        \n",
    "        e2=sr_ds_json(df_u,'asin','reviewerID',self.item,self.user)# 同一个 item 字典\n",
    "        \n",
    "        print(\"edge u2i loaded\")\n",
    "        e2_mask=get_mask(e2,int(e2[0].shape[0]*0.15))\n",
    "        \n",
    "#         e2_train=e1[e1_mask]   ## 训练的边\n",
    "        \n",
    "#         e2_test=e1[1-e1_mask]   #测试的边\n",
    "        sr2,ds2=e2\n",
    "    \n",
    "        self.train_idx = torch.nonzero(e2_mask, as_tuple=False).squeeze()#选择的边\n",
    "        self.test_idx,self.val_idx = torch.split(torch.nonzero(1-e2_mask, as_tuple=False).squeeze(),int(e2[0].shape[0]*0.1))\n",
    "        \n",
    "        \n",
    "        sr2_train=sr2[self.train_idx]\n",
    "        ds2_train=ds2[self.train_idx]\n",
    "        \n",
    "        self.val_edge=(sr2[self.val_idx],ds2[self.val_idx])\n",
    "        self.test_edge=(sr2[self.test_idx],ds2[self.test_idx])\n",
    "        \n",
    "        s1=('item','iagg','tag')\n",
    "        s2=('item','iagg','user')#中间节点 T\n",
    "        \n",
    "        torch.save([self.val_edge,self.test_edge],self.g_evl)\n",
    "#         print(e1)\n",
    "#         print(e2)\n",
    "#         print(e2[0][self.train_idx])\n",
    "#         sr3,ds3=con_sr_ds(e1,(sr2_train,ds2_train))# T 2i   #可以优化一下w\n",
    "#         print(\"edge u2t loaded\")\n",
    "\n",
    "#         s4=('item','neig','item')#中间节点 I ,T，U\n",
    "        s4=('tag','tagg','item')\n",
    "        \n",
    "        s5=('user','uagg','item')\n",
    "        \n",
    "\n",
    "        del self.item\n",
    "        del self.tag\n",
    "        del self.user\n",
    "        gc.collect()\n",
    "        \n",
    "#         e4=(sr4,ds4)\n",
    "        graphs=dgl.heterograph({   ##图节点 和 边\n",
    "            s1:(sr1,ds1),\n",
    "            s2:(sr2_train,ds2_train),\n",
    "            s4:(ds1,sr1),\n",
    "            s5:(ds2_train,sr2_train),\n",
    "        })\n",
    "        \n",
    "        \n",
    "        \n",
    "        dgl.save_graphs(self.g_path,graphs)\n",
    "        \n",
    "        return [[graphs]]\n",
    "#         self.graphs.edges[s3].data['w']=w\n",
    "\n",
    "#         self.graphs.edges[s6].data['w']=w\n",
    "#         self.graphs.nodes['user'].data['h']=torch.rand(self.graphs.num_nodes('user'),128)\n",
    "#         self.graphs.nodes['tag'].data['h']=torch.rand(self.graphs.num_nodes('tag'),128)\n",
    "#         self.graphs.nodes['item'].data['h']=torch.rand(self.graphs.num_nodes('item'),128)\n",
    "#         self.train_edges=self.graphs[s2].edges(form='eid')[dataset.train_idx]\n",
    "#         self.test_edges=self.graphs[s2].edges(form='eid')[dataset.test_idx]\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        assert idx==0\n",
    "        return self.graphs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78a227c2-9d4a-4555-a1bb-596d00eea240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_ds(df):\n",
    "#     print(ds)\n",
    "    sr =[]\n",
    "    ds=[]\n",
    "    num=0\n",
    "    for x in tqdm(df[0]):\n",
    "        s=x.split(' ')\n",
    "        if s[1]=='':\n",
    "            continue\n",
    "        s=list(map(int,s))\n",
    "        \n",
    "        sr.extend([s[0]]*(len(s)-1))\n",
    "        ds.extend(s[1:])\n",
    "        num+=len(s)-1\n",
    "    print(num)\n",
    "    return torch.tensor(sr),torch.tensor(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(3.9.2)",
   "language": "python",
   "name": "env-3.9.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
